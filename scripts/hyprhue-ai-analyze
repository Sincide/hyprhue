#!/bin/bash

# HyprHue - AI Wallpaper Analysis
# This script analyzes wallpapers using Ollama and vision models

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m'

# Configuration
CONFIG_DIR="${HOME}/.config/hyprhue"
CACHE_DIR="${HOME}/.cache/hyprhue"
CONFIG_FILE="${CONFIG_DIR}/config.toml"

# Default settings
DEFAULT_MODEL="llava:7b"
DEFAULT_TIMEOUT=30
OLLAMA_HOST="http://localhost:11434"

# Logging functions
log_info() {
    echo -e "${CYAN}[INFO]${NC} ${1}" >&2
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} ${1}" >&2
}

log_error() {
    echo -e "${RED}[ERROR]${NC} ${1}" >&2
}

log_debug() {
    if [[ "${DEBUG:-false}" == "true" ]]; then
        echo -e "${BLUE}[DEBUG]${NC} ${1}" >&2
    fi
}

# Show help
show_help() {
    cat << EOF
HyprHue - AI Wallpaper Analysis

Usage: $0 [OPTIONS] WALLPAPER

Arguments:
  WALLPAPER         Path to wallpaper image file

Options:
  -p, --prompt TEXT Optional natural language prompt for theming style
  -o, --output FILE Output file for JSON results (default: stdout)
  -m, --model NAME  AI model to use (default: ${DEFAULT_MODEL})
  -t, --timeout SEC Timeout in seconds (default: ${DEFAULT_TIMEOUT})
  -d, --debug       Enable debug output
  -h, --help        Show this help message

Examples:
  $0 wallpaper.jpg
  $0 wallpaper.jpg -p "make it warm and cozy"
  $0 wallpaper.jpg -o analysis.json
  $0 wallpaper.jpg -m llava:13b -t 60
EOF
}

# Parse command line arguments
parse_args() {
    WALLPAPER=""
    PROMPT=""
    OUTPUT=""
    MODEL="${DEFAULT_MODEL}"
    TIMEOUT="${DEFAULT_TIMEOUT}"
    DEBUG=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            -p|--prompt)
                PROMPT="$2"
                shift 2
                ;;
            -o|--output)
                OUTPUT="$2"
                shift 2
                ;;
            -m|--model)
                MODEL="$2"
                shift 2
                ;;
            -t|--timeout)
                TIMEOUT="$2"
                shift 2
                ;;
            -d|--debug)
                DEBUG=true
                shift
                ;;
            -h|--help)
                show_help
                exit 0
                ;;
            -*)
                log_error "Unknown option: $1"
                show_help
                exit 1
                ;;
            *)
                if [[ -z "${WALLPAPER}" ]]; then
                    WALLPAPER="$1"
                else
                    log_error "Unexpected argument: $1"
                    show_help
                    exit 1
                fi
                shift
                ;;
        esac
    done
    
    if [[ -z "${WALLPAPER}" ]]; then
        log_error "No wallpaper specified"
        show_help
        exit 1
    fi
}

# Check if Ollama is running
check_ollama() {
    log_info "Checking Ollama connection..."
    
    if ! curl -s "${OLLAMA_HOST}/api/tags" &>/dev/null; then
        log_error "Cannot connect to Ollama at ${OLLAMA_HOST}"
        log_error "Please ensure Ollama is running:"
        log_error "  sudo systemctl start ollama"
        exit 1
    fi
    
    log_success "Ollama is running"
}

# Check if model is available
check_model() {
    log_info "Checking if model ${MODEL} is available..."
    
    if ! curl -s "${OLLAMA_HOST}/api/tags" | jq -r '.models[].name' | grep -q "^${MODEL}$"; then
        log_error "Model ${MODEL} is not available"
        log_error "Please pull the model first:"
        log_error "  ollama pull ${MODEL}"
        exit 1
    fi
    
    log_success "Model ${MODEL} is available"
}

# Convert image to base64
image_to_base64() {
    local image_path="$1"
    
    log_info "Converting image to base64..."
    
    if [[ ! -f "${image_path}" ]]; then
        log_error "Image file not found: ${image_path}"
        exit 1
    fi
    
    # Convert to base64
    base64 -w 0 "${image_path}"
}

# Create AI prompt
create_prompt() {
    local user_prompt="$1"
    
    local base_prompt="Analyze this wallpaper image and extract a color palette suitable for a desktop theme. Focus on the dominant colors, accent colors, and overall mood.

Please provide a response in JSON format with the following structure:
{
  \"palette\": {
    \"primary\": \"#hexcolor\",
    \"secondary\": \"#hexcolor\",
    \"accent\": \"#hexcolor\",
    \"background\": \"#hexcolor\",
    \"foreground\": \"#hexcolor\",
    \"success\": \"#hexcolor\",
    \"warning\": \"#hexcolor\",
    \"error\": \"#hexcolor\"
  },
  \"mood\": \"description of the overall mood/feeling\",
  \"style\": \"description of the visual style\",
  \"suggestions\": [
    \"specific theming suggestions\"
  ]
}"
    
    if [[ -n "${user_prompt}" ]]; then
        echo "${base_prompt}

Additional styling request: ${user_prompt}"
    else
        echo "${base_prompt}"
    fi
}

# Call Ollama API
call_ollama() {
    local image_base64="$1"
    local prompt="$2"
    
    log_info "Analyzing wallpaper with AI model ${MODEL}..."
    
    # Create request payload
    local request_payload=$(jq -n \
        --arg model "${MODEL}" \
        --arg prompt "${prompt}" \
        --arg image "${image_base64}" \
        '{
            model: $model,
            prompt: $prompt,
            images: [$image],
            stream: false,
            options: {
                temperature: 0.7,
                top_p: 0.9,
                top_k: 40
            }
        }')
    
    log_debug "Request payload created"
    
    # Make API call
    local response
    response=$(curl -s \
        --max-time "${TIMEOUT}" \
        -X POST \
        -H "Content-Type: application/json" \
        -d "${request_payload}" \
        "${OLLAMA_HOST}/api/generate")
    
    if [[ $? -ne 0 ]]; then
        log_error "Failed to call Ollama API"
        exit 1
    fi
    
    log_debug "API response received"
    
    # Extract response content
    local content
    content=$(echo "${response}" | jq -r '.response // empty')
    
    if [[ -z "${content}" ]]; then
        log_error "Empty response from AI model"
        log_error "Raw response: ${response}"
        exit 1
    fi
    
    echo "${content}"
}

# Parse and validate AI response
parse_ai_response() {
    local ai_response="$1"
    
    log_info "Parsing AI response..."
    
    # Try to extract JSON from response
    local json_content
    json_content=$(echo "${ai_response}" | sed -n '/^{/,/^}/p' | head -n 1)
    
    if [[ -z "${json_content}" ]]; then
        # Try to find JSON block in markdown
        json_content=$(echo "${ai_response}" | sed -n '/```json/,/```/p' | sed '/```/d')
    fi
    
    if [[ -z "${json_content}" ]]; then
        log_error "No JSON found in AI response"
        log_error "Raw response: ${ai_response}"
        exit 1
    fi
    
    # Validate JSON
    if ! echo "${json_content}" | jq . &>/dev/null; then
        log_error "Invalid JSON in AI response"
        log_error "JSON content: ${json_content}"
        exit 1
    fi
    
    log_success "AI response parsed successfully"
    echo "${json_content}"
}

# Add metadata to result
add_metadata() {
    local json_content="$1"
    local wallpaper_path="$2"
    
    # Add metadata
    local enhanced_json
    enhanced_json=$(echo "${json_content}" | jq \
        --arg wallpaper "${wallpaper_path}" \
        --arg timestamp "$(date -Iseconds)" \
        --arg model "${MODEL}" \
        '. + {
            metadata: {
                wallpaper: $wallpaper,
                timestamp: $timestamp,
                model: $model,
                version: "1.0.0"
            }
        }')
    
    echo "${enhanced_json}"
}

# Main function
main() {
    parse_args "$@"
    
    log_info "Starting AI wallpaper analysis..."
    log_debug "Wallpaper: ${WALLPAPER}"
    log_debug "Prompt: ${PROMPT}"
    log_debug "Model: ${MODEL}"
    log_debug "Output: ${OUTPUT}"
    
    # Validate inputs
    if [[ ! -f "${WALLPAPER}" ]]; then
        log_error "Wallpaper file not found: ${WALLPAPER}"
        exit 1
    fi
    
    # Check dependencies
    check_ollama
    check_model
    
    # Process wallpaper
    local image_base64
    image_base64=$(image_to_base64 "${WALLPAPER}")
    
    local prompt
    prompt=$(create_prompt "${PROMPT}")
    
    local ai_response
    ai_response=$(call_ollama "${image_base64}" "${prompt}")
    
    local json_result
    json_result=$(parse_ai_response "${ai_response}")
    
    local final_result
    final_result=$(add_metadata "${json_result}" "${WALLPAPER}")
    
    # Output result
    if [[ -n "${OUTPUT}" ]]; then
        echo "${final_result}" > "${OUTPUT}"
        log_success "Analysis saved to ${OUTPUT}"
    else
        echo "${final_result}"
    fi
    
    log_success "AI analysis completed successfully"
}

# Run main function
main "$@" 